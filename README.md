<div id = "top"></div>

<div align="center">
  
[![](https://capsule-render.vercel.app/api?type=waving&height=200&color=0:0F172A,65:4F46E5,100:22D3EE&text=paperlist%20for%20medical%20MLLM&fontSize=50)](#top)

</div>


- [[2025-AAAI]](https://arxiv.org/pdf/2412.09278v2) **Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**
  - ç®€ä»‹ï¼ˆä¸­æ–‡ï¼‰:
  - MedPLIBï¼šå…¨çƒé¦–ä¸ªåƒç´ çº§åŒ»å­¦å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œç²¾å‡†å®šä½ç—…ç¶ï¼Œé¦–åˆ›MoEå¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œåˆ¶ä½œ31ä¸‡æ¡æ•°æ®çš„MeCoVQAæ•°æ®é›†ã€‚
  - Intro (EN):
  - MedPLIB: The world's first pixel-level medical multimodal large model, enabling precise lesion localization. It pioneers a novel Mixture of Experts (MoE) multi-stage training strategy and has developed the MeCoVQA dataset comprising 310,000 data entries.

<img width="1245" height="495" alt="image" src="https://github.com/user-attachments/assets/0d73a726-2e61-4ebd-9641-2d0a81ad4606" />

**ğŸ¦‰ Contributors: [Junjie Yang ( SCUT Undergraduate)](https://github.com/yangjj007), [Zixu Li ( HHU Undergraduate)](https://github.com/lzx060506), [Qiwei Yang ( WHU Undergraduate)](https://github.com/Archie9201), [Jingwen Chen ( ZUFE Postgraduate)](https://github.com/Ednaqvq), [Haoxuan Sun ( SMU Undergraduate)](https://github.com/burningcotton), [Chenxin Di ( ZUFE Postgraduate)](https://github.com/D-cx777)**
