<div id = "top"></div>

<div align="center">
  
[![](https://capsule-render.vercel.app/api?type=waving&height=200&color=0:0F172A,65:4F46E5,100:22D3EE&text=paperlist%20for%20medical%20MLLM&fontSize=50)](#top)

</div>


- [[2025-AAAI]](https://arxiv.org/pdf/2412.09278v2) **Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**
  - 简介（中文）:
  - MedPLIB：全球首个像素级医学多模态大模型，精准定位病灶，首创MoE多阶段训练策略，制作31万条数据的MeCoVQA数据集。
  - Intro (EN):
  - MedPLIB: The world's first pixel-level medical multimodal large model, enabling precise lesion localization. It pioneers a novel Mixture of Experts (MoE) multi-stage training strategy and has developed the MeCoVQA dataset comprising 310,000 data entries.

<img width="1245" height="495" alt="image" src="https://github.com/user-attachments/assets/0d73a726-2e61-4ebd-9641-2d0a81ad4606" />

**🦉 Contributors: [Junjie Yang ( SCUT Undergraduate)](https://github.com/yangjj007), [Zixu Li ( HHU Undergraduate)](https://github.com/lzx060506), [Qiwei Yang ( WHU Undergraduate)](https://github.com/Archie9201), [Jingwen Chen ( ZUFE Postgraduate)](https://github.com/Ednaqvq), [Haoxuan Sun ( SMU Undergraduate)](https://github.com/burningcotton), [Chenxin Di ( ZUFE Postgraduate)](https://github.com/D-cx777)**
